{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Loading dataset from local disk...\n",
      "Dataset loaded from local disk.\n",
      "Dataset preparing\n",
      "Train data size: 1000\n",
      "Evaluation data size: 1000\n",
      "done\n",
      "ROUGE Score: {'rouge-1': {'r': 0.2517467263193698, 'p': 0.10449615256322187, 'f': 0.144403534904559}, 'rouge-2': {'r': 0.0335487556787004, 'p': 0.011295964763606652, 'f': 0.01639923082383876}, 'rouge-l': {'r': 0.20085080797869231, 'p': 0.08306493580539231, 'f': 0.11479753671209264}}\n",
      "\n",
      "ROUGE Score (Pre-trained Model): 0.11479753671209264\n",
      "Epoch: 1/1, Training Loss: 259.8775\n",
      "ROUGE Score: {'rouge-1': {'r': 0.25087947493771123, 'p': 0.10432261711866546, 'f': 0.14423557594271008}, 'rouge-2': {'r': 0.033515552139916374, 'p': 0.011090959721455492, 'f': 0.016338473540057054}, 'rouge-l': {'r': 0.2009444200972446, 'p': 0.08324854983230438, 'f': 0.11516210407238227}}\n",
      "ROUGE Score: {'rouge-1': {'r': 0.25087947493771123, 'p': 0.10432261711866546, 'f': 0.14423557594271008}, 'rouge-2': {'r': 0.033515552139916374, 'p': 0.011090959721455492, 'f': 0.016338473540057054}, 'rouge-l': {'r': 0.2009444200972446, 'p': 0.08324854983230438, 'f': 0.11516210407238227}}\n",
      "\n",
      "ROUGE Score (Trained Model): 0.11516210407238227\n",
      "\n",
      "ROUGE Score Improvement: 0.0004\n",
      "Summary: he yowled a very spooky sound whenever he yowled that sound lightening struckeven though the sounds were so loud the family were still asleep well asleep except for two molly and holly the 9 year old twins. the family were still asleep well asleep except for two molly and holly the 9 year old twins.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from rouge import Rouge\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Check for CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# XSum Dataset (Small Subset)\n",
    "dataset_path = \"xsum_dataset\"\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(\"Downloading dataset...\")\n",
    "    # Download and save the full dataset (if needed for future training)\n",
    "    dataset = load_dataset(\"xsum\")\n",
    "    dataset.save_to_disk(dataset_path)\n",
    "    print(\"Dataset downloaded and saved locally.\")\n",
    "else:\n",
    "    print(\"Loading dataset from local disk...\")\n",
    "    dataset = load_from_disk(dataset_path)\n",
    "    print(\"Dataset loaded from local disk.\")\n",
    "\n",
    "print(\"Dataset preparing\")\n",
    "\n",
    "# Create a small subset for evaluation and training (adjust split size as needed)\n",
    "train_size = 0.6  # Use a small portion for faster evaluation and training\n",
    "dataset_split = dataset[\"train\"].train_test_split(test_size=1 - train_size, shuffle=True)\n",
    "train_data = dataset_split[\"train\"]\n",
    "eval_data = dataset_split[\"test\"]\n",
    "print(f\"Train data size: {len(train_data)}\")\n",
    "print(f\"Evaluation data size: {len(eval_data)}\")\n",
    "print(\"done\")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        cleaned_text = clean_text(sample[\"document\"])\n",
    "        input_ids = tokenize_text(cleaned_text, self.tokenizer).squeeze()\n",
    "        summary = tokenize_text(sample[\"summary\"], self.tokenizer).squeeze()  # Tokenize the summary as well if needed\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"labels\": summary}\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<[^>]+>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # Remove non-alphanumeric characters\n",
    "    return text\n",
    "\n",
    "def tokenize_text(text, tokenizer):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)[\"input_ids\"]\n",
    "    return input_ids\n",
    "\n",
    "def evaluate_model(model, data_loader, tokenizer):\n",
    "    rouge = Rouge()\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    predictions = []\n",
    "    references = []\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Generate summary\n",
    "        summary_ids = model.generate(\n",
    "            input_ids=input_ids, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True\n",
    "        )\n",
    "        # Decode summaries\n",
    "        for summary_id in summary_ids:\n",
    "            summary = tokenizer.decode(summary_id, skip_special_tokens=True)\n",
    "            predictions.append(summary)\n",
    "\n",
    "        for label in labels:\n",
    "            reference = tokenizer.decode(label, skip_special_tokens=True)\n",
    "            references.append(reference)\n",
    "\n",
    "    # Calculate ROUGE score\n",
    "    rouge_score = rouge.get_scores(predictions, references, avg=True)\n",
    "    print(f\"ROUGE Score: {rouge_score}\")\n",
    "    return rouge_score[\"rouge-l\"][\"f\"]\n",
    "\n",
    "def train_model(model, train_data, tokenizer, epochs=2, batch_size=1, gradient_accumulation_steps=5):\n",
    "    optimizer = Adam(model.parameters(), lr=1e-5)  # Adjust learning rate as needed\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    training_loss = []  # Track training loss for visualization (optional)\n",
    "    best_rouge = 0  # Track best ROUGE score for early stopping (optional)\n",
    "    patience = 3  # Number of epochs to wait for improvement before stopping (optional)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        # Create DataLoader for the training data\n",
    "        train_dataset = CustomDataset(train_data, tokenizer)\n",
    "        train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for step, batch in enumerate(train_data_loader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, labels=labels)\n",
    "            loss = outputs.loss / gradient_accumulation_steps  # Normalize loss\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient accumulation\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Print training loss\n",
    "        print(f\"Epoch: {epoch+1}/{epochs}, Training Loss: {epoch_loss:.4f}\")\n",
    "        training_loss.append(epoch_loss)  # Track training loss (optional)\n",
    "\n",
    "        # Evaluate model on validation set (optional)\n",
    "        eval_dataset = CustomDataset(eval_data, tokenizer)\n",
    "        eval_data_loader = DataLoader(eval_dataset, batch_size=1)\n",
    "        val_rouge = evaluate_model(model, eval_data_loader, tokenizer)\n",
    "\n",
    "        # Early stopping (optional)\n",
    "        if val_rouge > best_rouge:\n",
    "            best_rouge = val_rouge\n",
    "            patience = 3  # Reset patience counter\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience == 0:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "    return model  # Return the trained model\n",
    "\n",
    "# Pre-trained Model Selection (T5-Tiny)\n",
    "model_name = \"t5-small\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.to(device)  # Move model to appropriate device\n",
    "\n",
    "# Evaluate the pre-trained model on the evaluation set\n",
    "eval_dataset = CustomDataset(eval_data, tokenizer)\n",
    "eval_data_loader = DataLoader(eval_dataset, batch_size=1)\n",
    "pre_trained_rouge = evaluate_model(model, eval_data_loader, tokenizer)\n",
    "print(f\"\\nROUGE Score (Pre-trained Model): {pre_trained_rouge}\")\n",
    "\n",
    "# Train the model (adjust epochs, batch size, and gradient accumulation steps for desired training time and memory constraints)\n",
    "trained_model = train_model(model, train_data, tokenizer, epochs=1, batch_size=2, gradient_accumulation_steps=16)\n",
    "\n",
    "# Evaluate the trained model on the evaluation set\n",
    "trained_rouge = evaluate_model(trained_model, eval_data_loader, tokenizer)\n",
    "print(f\"\\nROUGE Score (Trained Model): {trained_rouge}\")\n",
    "\n",
    "print(f\"\\nROUGE Score Improvement: {trained_rouge - pre_trained_rouge:.4f}\")\n",
    "\n",
    "def summarize_text(text_to_summarize, trained_model, tokenizer):\n",
    "    cleaned_text = clean_text(text_to_summarize)\n",
    "    input_ids = tokenize_text(cleaned_text, tokenizer).to(device)\n",
    "\n",
    "    summary_ids = trained_model.generate(\n",
    "        input_ids, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Optional: Summarize Text Using Trained Model\n",
    "text_to_summarize = \"\"\"\n",
    "Once on a very dark, cold night there lived the Nicholls family.  They were a kind hearted, happy family.\n",
    "Their house was quite grand but there was only one thing about their house, their house was a ……………. HAUNTED HOUSE!!\n",
    "The story begins with all the Nicholls family fast asleep in their warm cosy beds.  During the night when the clock struck midnight, \n",
    "a silvery white ghost appeared.  After the ghost appeared, he yowled a very spooky sound.  Whenever he yowled that sound, lightening struck!\\\n",
    "Even though the sounds were so loud, the family were still asleep.  Well asleep except for two – Molly and Holly, the 9 year old twins.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_text(text_to_summarize, trained_model, tokenizer)\n",
    "print(f\"Summary: {summary}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
