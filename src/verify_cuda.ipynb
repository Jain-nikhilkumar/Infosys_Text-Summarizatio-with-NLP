
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available torch Version 2.3.1\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "Number of CUDA devices: 1\n",
      "CUDA device name: NVIDIA GeForce GTX 1650 Ti\n",
      "Tensor on GPU: tensor([[9.7728e-01, 5.8615e-01, 8.4063e-01],\n",
      "        [6.0081e-02, 8.1730e-01, 8.4043e-05],\n",
      "        [7.1410e-01, 1.8492e-01, 3.9295e-01]], device='cuda:0')\n",
      "nvidia-smi output:\n",
      "\n",
      "Wed Jun 19 23:43:54 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 522.06       Driver Version: 522.06       CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   69C    P0    37W /  N/A |   3918MiB /  4096MiB |     31%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      5808    C+G   ...592.61\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      7308    C+G   ...Device\\asus_framework.exe    N/A      |\n",
      "|    0   N/A  N/A     10204    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11280    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13656      C   ...min\\miniconda3\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     14452    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     15564    C+G   ...werToys.ColorPickerUI.exe    N/A      |\n",
      "|    0   N/A  N/A     15728    C+G   ...\\PowerToys.FancyZones.exe    N/A      |\n",
      "|    0   N/A  N/A     16128    C+G   ...pps\\PowerToys.Peek.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     16340    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     16452    C+G   ...werToys.PowerLauncher.exe    N/A      |\n",
      "|    0   N/A  N/A     17384      C   ...min\\miniconda3\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "\n",
    "\n",
    "print(\"Available torch Version\",torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "print(\"CUDA device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA device\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tensor = torch.rand(3, 3).cuda()\n",
    "    print(\"Tensor on GPU:\", tensor)\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "\n",
    "\n",
    "def print_nvidia_smi():\n",
    "    try:\n",
    "        # Run the nvidia-smi command\n",
    "        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        \n",
    "        # Check if the command was successful\n",
    "        if result.returncode == 0:\n",
    "            print(\"nvidia-smi output:\\n\")\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(f\"nvidia-smi failed with error code {result.returncode}\")\n",
    "            print(result.stderr)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"nvidia-smi command not found. Make sure NVIDIA drivers are installed.\")\n",
    "\n",
    "# Call the function to print nvidia-smi output\n",
    "print_nvidia_smi()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
