{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text\n",
      "\n",
      "    Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence \n",
      "    concerned with the interactions between computers and human language, in particular how to program computers to \n",
      "    process and analyze large amounts of natural language data. Challenges in natural language processing frequently \n",
      "    involve speech recognition, natural language understanding, and natural language generation.\n",
      "    \n",
      "Summary:\n",
      "natural language processing nlp subfield linguistics computer science artificial intelligence concerned interactions computers human language particular program computers process analyze large amounts natural language data challenges natural language processing frequently involve speech recognition natural language understanding natural language generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Download required NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Tokenize each sentence into words\n",
    "    words = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "    \n",
    "    # Remove stopwords and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words_filtered = [[word for word in sentence if word not in stop_words and word not in string.punctuation] for sentence in words]\n",
    "    \n",
    "    # Join words back into sentences\n",
    "    sentences_filtered = [' '.join(sentence) for sentence in words_filtered]\n",
    "    \n",
    "    return sentences_filtered\n",
    "\n",
    "def tfidf_summarize(text, num_sentences=2):\n",
    "    # Preprocess the text\n",
    "    sentences = preprocess_text(text)\n",
    "    \n",
    "    # Create the TF-IDF vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "    \n",
    "    # Calculate sentence scores (sum of TF-IDF values)\n",
    "    sentence_scores = np.array(tfidf_matrix.sum(axis=1)).flatten()\n",
    "    \n",
    "    # Sort sentences by their scores in descending order\n",
    "    sorted_indices = np.argsort(-sentence_scores)\n",
    "    \n",
    "    # Select the top sentences\n",
    "    top_sentence_indices = sorted_indices[:num_sentences]\n",
    "    top_sentence_indices.sort()  # sort by their original order\n",
    "    \n",
    "    # Extract and return the top sentences\n",
    "    summary_sentences = [sentences[i] for i in top_sentence_indices]\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == '__main__':\n",
    "    # Example text\n",
    "    example_text = \"\"\"\n",
    "    Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence \n",
    "    concerned with the interactions between computers and human language, in particular how to program computers to \n",
    "    process and analyze large amounts of natural language data. Challenges in natural language processing frequently \n",
    "    involve speech recognition, natural language understanding, and natural language generation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Summarize the text\n",
    "    print(\"Original Text\")\n",
    "    print(example_text)\n",
    "    summary = tfidf_summarize(example_text, num_sentences=2)\n",
    "    print(\"Summary:\")\n",
    "    print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
